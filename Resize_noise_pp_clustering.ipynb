{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import matplotlib.image as mpimg\n",
    "from random import choice\n",
    "from math import log\n",
    "from skimage.filters import unsharp_mask\n",
    "from skimage import io, morphology\n",
    "from skimage import exposure\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_gaussian_noise(image, mean=0, sigma=25):\n",
    "#Aggiunge rumore gaussiano all'immagine\n",
    "    row, col= image.shape\n",
    "    noise = np.random.normal(mean, sigma, (row, col))\n",
    "    noisy_image = np.clip(image + noise, 0, 1)\n",
    "    return noisy_image\n",
    "\n",
    "def equalize_within_mask(image, mask, range_min=0, range_max=1):\n",
    "    # Applica la maschera all'immagine\n",
    "    masked_image = np.copy(image)\n",
    "    masked_image[~mask] = 0\n",
    "\n",
    "    # Calcola l'istogramma dell'immagine all'interno della maschera\n",
    "    hist, bin_centers = exposure.histogram(masked_image)\n",
    "\n",
    "    # Equalizza l'istogramma all'interno del range specificato\n",
    "    equalized_image = exposure.rescale_intensity(masked_image, in_range='image', out_range = (range_min,range_max))\n",
    "\n",
    "    image_to_add = np.copy(image)\n",
    "    image_to_add[mask] = 0\n",
    "    equalized_image = equalized_image + image_to_add\n",
    "\n",
    "    return equalized_image\n",
    "\n",
    "def low_pass(img,size):\n",
    "\n",
    "    kernel = np.ones((size,size))\n",
    "    kernel = kernel/(size**2)\n",
    "    filtered_img = convolve2d(img, kernel, mode='same', boundary='symm')\n",
    "    return filtered_img\n",
    "\n",
    "def enchance_contrast(img,f):\n",
    "\n",
    "    media = np.mean(img)\n",
    "    diff = img - np.array(media)\n",
    "    img_con = img + f*diff\n",
    "    img_con[img_con < 0] = 0\n",
    "    img_con[img_con > 1] = 1\n",
    "\n",
    "    return img_con\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    return new_image\n",
    "def gaussian_kernel(size, sigma):\n",
    "    \"\"\"\n",
    "    Crea un kernel gaussiano 2D.\n",
    "    \"\"\"\n",
    "    kernel = np.fromfunction(\n",
    "        lambda x, y: (1/(2*np.pi*sigma**2)) * np.exp(-((x - size//2)**2 + (y - size//2)**2)/(2*sigma**2)),\n",
    "        (size, size)\n",
    "    )\n",
    "    return kernel / np.sum(kernel)\n",
    "\n",
    "def gaussian_blur(image, kernel_size, sigma):\n",
    "    \"\"\"\n",
    "    Applica un filtro gaussiano all'immagine utilizzando il kernel definito.\n",
    "    \"\"\"\n",
    "    # Crea il kernel gaussiano\n",
    "    kernel = gaussian_kernel(kernel_size, sigma)\n",
    "    \n",
    "    # Applica la convoluzione tra l'immagine e il kernel gaussiano\n",
    "    blurred_image = cv2.filter2D(image, -1, kernel)\n",
    "    \n",
    "    return blurred_image\n",
    "\n",
    "def balance_luminosity_add(img,mask,kernel_size,difference):\n",
    "\n",
    "    size = np.shape(img)[0]\n",
    "    kernel = np.ones((kernel_size,kernel_size))\n",
    "\n",
    "    media_im = np.mean(img[mask])\n",
    "\n",
    "    binary_mask = np.zeros(np.shape(mask))\n",
    "    binary_mask[mask] = 1\n",
    "\n",
    "    trsh = (kernel_size**2)/2\n",
    "    available_pos = []\n",
    "\n",
    "    for i in range(0,size-kernel_size,int(kernel_size/2)):\n",
    "        for j in range(0,size-kernel_size,int(kernel_size/2)):\n",
    "            check_pos = np.sum(binary_mask[i:i+kernel_size,j:j+kernel_size] * kernel)\n",
    "            if check_pos > trsh: \n",
    "                available_pos.append((i,j))\n",
    "\n",
    "    new_image = np.copy(img)            \n",
    "\n",
    "    for coords in available_pos:\n",
    "        y = coords[0]\n",
    "        x = coords[1]\n",
    "        media_loc = np.mean(img[y:y+kernel_size,x:x+kernel_size])\n",
    "        if abs(media_loc-media_im) >difference:\n",
    "            correzione_l = (media_im - media_loc)/10\n",
    "            patch = new_image[y:y+kernel_size,x:x+kernel_size] + correzione_l\n",
    "            patch[patch < 0] = 0.\n",
    "            patch[patch > 1] = 1.0\n",
    "            new_image[y:y+kernel_size,x:x+kernel_size] = patch\n",
    "\n",
    "    return new_image\n",
    "\n",
    "\n",
    "def pre_process(img):\n",
    "    mask_cerchio = img < 0.00784 \n",
    "    img[mask_cerchio] = 1.0\n",
    "    \n",
    "    img_gamma = img ** log(0.5,np.mean(img[~mask_cerchio]))\n",
    "    img_f = gaussian_blur(img_gamma, kernel_size=9, sigma=1)\n",
    "    img_f[mask_cerchio] = np.mean(img_f[~mask_cerchio])\n",
    "    img_con = enchance_contrast(img_f,-0.1)\n",
    "    img_sh =  unsharp_mask(img_con, radius=18, amount=4)\n",
    "    img_sh[mask_cerchio] = np.mean(img_sh[~mask_cerchio])\n",
    "    img_con_2 = enchance_contrast(img_sh, 0.2)\n",
    "    mask_bianchi = img_con_2 > np.percentile(img_con_2[~mask_cerchio],96)\n",
    "    selem_2 = morphology.disk(24)\n",
    "    closing = morphology.dilation(mask_bianchi, selem_2)\n",
    "    img_con_2[closing] = img_con_2[closing] ** log(0.6,np.mean(img_con_2[closing]))\n",
    "    img_e = equalize_within_mask(img_con_2,~mask_cerchio)\n",
    "    img_std = (img_e - np.mean(img_e[~mask_cerchio]))/np.std(img_e[~mask_cerchio])\n",
    "    img_std = (img_std - np.min(img_std[~mask_cerchio])) / (np.max(img_std[~mask_cerchio])- np.min(img_std[~mask_cerchio]))\n",
    "    img_std[mask_cerchio] = 1.0\n",
    "    return img_std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PREPROCESS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_input = 'C:\\\\Users\\\\Lenovo\\\\OneDrive\\\\Desktop\\\\univesita\\\\Elaborazione immagini biomediche\\\\RETINA\\\\Original'\n",
    "path_output = 'C:\\\\Users\\\\Lenovo\\\\OneDrive\\\\Desktop\\\\Prova'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:3504: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "c:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\numpy\\core\\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 14\u001b[0m\n\u001b[0;32m     12\u001b[0m img_rsz \u001b[38;5;241m=\u001b[39m img_o\u001b[38;5;241m.\u001b[39mresize((dim, \u001b[38;5;28mint\u001b[39m(dim \u001b[38;5;241m*\u001b[39m choice(aspect_ratio))))\n\u001b[0;32m     13\u001b[0m img_g \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(img_rsz)[:,:,\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m256\u001b[39m\n\u001b[1;32m---> 14\u001b[0m img_p\u001b[38;5;241m=\u001b[39m \u001b[43mpre_process\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg_g\u001b[49m\u001b[43m)\u001b[49m                       \u001b[38;5;66;03m# Penso che il preprocess vada fatto a questo punto\u001b[39;00m\n\u001b[0;32m     15\u001b[0m img_no \u001b[38;5;241m=\u001b[39m add_gaussian_noise(img_p,choice(medie_rumore), choice(sigme_rumore))\n\u001b[0;32m     16\u001b[0m img_8 \u001b[38;5;241m=\u001b[39m (img_no\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m255\u001b[39m)\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39muint8)\n",
      "Cell \u001b[1;32mIn[7], line 117\u001b[0m, in \u001b[0;36mpre_process\u001b[1;34m(img)\u001b[0m\n\u001b[0;32m    115\u001b[0m mask_bianchi \u001b[38;5;241m=\u001b[39m img_con_2 \u001b[38;5;241m>\u001b[39m np\u001b[38;5;241m.\u001b[39mpercentile(img_con_2[\u001b[38;5;241m~\u001b[39mmask_cerchio],\u001b[38;5;241m96\u001b[39m)\n\u001b[0;32m    116\u001b[0m selem_2 \u001b[38;5;241m=\u001b[39m morphology\u001b[38;5;241m.\u001b[39mdisk(\u001b[38;5;241m24\u001b[39m)\n\u001b[1;32m--> 117\u001b[0m closing \u001b[38;5;241m=\u001b[39m \u001b[43mmorphology\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmask_bianchi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mselem_2\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    118\u001b[0m img_con_2[closing] \u001b[38;5;241m=\u001b[39m img_con_2[closing] \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m log(\u001b[38;5;241m0.6\u001b[39m,np\u001b[38;5;241m.\u001b[39mmean(img_con_2[closing]))\n\u001b[0;32m    119\u001b[0m img_e \u001b[38;5;241m=\u001b[39m equalize_within_mask(img_con_2,\u001b[38;5;241m~\u001b[39mmask_cerchio)\n",
      "File \u001b[1;32mc:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\skimage\\morphology\\misc.py:38\u001b[0m, in \u001b[0;36mdefault_footprint.<locals>.func_out\u001b[1;34m(image, footprint, *args, **kwargs)\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m footprint \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     37\u001b[0m     footprint \u001b[38;5;241m=\u001b[39m ndi\u001b[38;5;241m.\u001b[39mgenerate_binary_structure(image\u001b[38;5;241m.\u001b[39mndim, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m---> 38\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfootprint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfootprint\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\skimage\\morphology\\gray.py:321\u001b[0m, in \u001b[0;36mdilation\u001b[1;34m(image, footprint, out, shift_x, shift_y)\u001b[0m\n\u001b[0;32m    314\u001b[0m \u001b[38;5;66;03m# Inside ndi.grey_dilation, the footprint is inverted,\u001b[39;00m\n\u001b[0;32m    315\u001b[0m \u001b[38;5;66;03m# e.g. `footprint = footprint[::-1, ::-1]` for 2D [1]_, for reasons unknown\u001b[39;00m\n\u001b[0;32m    316\u001b[0m \u001b[38;5;66;03m# to this author (@jni). To \"patch\" this behaviour, we invert our own\u001b[39;00m\n\u001b[0;32m    317\u001b[0m \u001b[38;5;66;03m# footprint before passing it to `ndi.grey_dilation`.\u001b[39;00m\n\u001b[0;32m    318\u001b[0m \u001b[38;5;66;03m# [1] https://github.com/scipy/scipy/blob/ec20ababa400e39ac3ffc9148c01ef86d5349332/scipy/ndimage/morphology.py#L1285  # noqa\u001b[39;00m\n\u001b[0;32m    319\u001b[0m footprint \u001b[38;5;241m=\u001b[39m _invert_footprint(footprint)\n\u001b[1;32m--> 321\u001b[0m \u001b[43mndi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgrey_dilation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfootprint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfootprint\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    322\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[1;32mc:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\ndimage\\_morphology.py:1378\u001b[0m, in \u001b[0;36mgrey_dilation\u001b[1;34m(input, size, footprint, structure, output, mode, cval, origin)\u001b[0m\n\u001b[0;32m   1375\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m sz \u001b[38;5;241m&\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   1376\u001b[0m         origin[ii] \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m-> 1378\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_filters\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_min_or_max_filter\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfootprint\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstructure\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1379\u001b[0m \u001b[43m                                   \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morigin\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\ndimage\\_filters.py:1231\u001b[0m, in \u001b[0;36m_min_or_max_filter\u001b[1;34m(input, size, footprint, structure, output, mode, cval, origin, minimum, axes)\u001b[0m\n\u001b[0;32m   1227\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m   1228\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mA sequence of modes is not supported for non-separable \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1229\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfootprints\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1230\u001b[0m     mode \u001b[38;5;241m=\u001b[39m _ni_support\u001b[38;5;241m.\u001b[39m_extend_mode_to_code(mode)\n\u001b[1;32m-> 1231\u001b[0m     \u001b[43m_nd_image\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmin_or_max_filter\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfootprint\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstructure\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1232\u001b[0m \u001b[43m                                \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morigins\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mminimum\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1233\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m temp_needed:\n\u001b[0;32m   1234\u001b[0m     temp[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m] \u001b[38;5;241m=\u001b[39m output\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "lista_im = os.listdir(path_input)\n",
    "medie_rumore = [-0.1,0,0,0, 0.1]\n",
    "sigme_rumore = [0.07,0.05, 0.02]\n",
    "aspect_ratio = [1,1,3/4,9/16, 2/3]\n",
    "sizes = [3500, 2048, 1024,512]\n",
    "\n",
    "\n",
    "for im in lista_im:\n",
    "    image_path = os.path.join(path_input, im)\n",
    "    img_o = Image.open(image_path)\n",
    "    dim = choice(sizes)\n",
    "    img_rsz = img_o.resize((dim, int(dim * choice(aspect_ratio))))\n",
    "    img_g = np.array(img_rsz)[:,:,1]/255\n",
    "    #img_p= pre_process(img_g)           # Penso che il preprocess vada fatto a questo punto\n",
    "    img_no = add_gaussian_noise(img_g,choice(medie_rumore), choice(sigme_rumore))  #CAMBIARE img_g con img_p se preprocess\n",
    "    img_8 = (img_no*255).astype(np.uint8)\n",
    "    img_to_save = Image.fromarray(img_8)\n",
    "    img_to_save.save(os.path.join(path_output,im))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CLUSTERING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1428816432.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[18], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    pip install skan\u001b[0m\n\u001b[1;37m        ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "#!pip install skan\n",
    "\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "from skimage import img_as_ubyte, measure, morphology, feature, color\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from skan import Skeleton, summarize\n",
    "from sklearn.model_selection import train_test_split\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcola_vasi_per_tipo(img):\n",
    "\n",
    "  if np.max(img) == 0:\n",
    "    print('immagine vuota')\n",
    "    return 0, 0\n",
    "  skt = skeletonize(img)\n",
    "\n",
    "  skeleton_data = Skeleton(skt)\n",
    "  skel_summary = summarize(skeleton_data)\n",
    "\n",
    "  # count how many branches have branch-type = 1 and 2\n",
    "  N_J2E = len(skel_summary[skel_summary['branch-type'] == 1])\n",
    "  N_J2J = len(skel_summary[skel_summary['branch-type'] == 2])\n",
    "\n",
    "  return N_J2E, N_J2J\n",
    "\n",
    "def calculate_glcm_features(gray_image):\n",
    "    # Specify the distances and angles for GLCM\n",
    "    distances = [3, 7, 11]\n",
    "    angles = [0, np.pi/4, np.pi/2, 3*np.pi/4]\n",
    "\n",
    "    # Calculate GLCM\n",
    "    glcm = greycomatrix(gray_image, distances=distances, angles=angles, symmetric=True, normed=True)\n",
    "\n",
    "    # Calculate GLCM features\n",
    "    contrast = np.mean(greycoprops(glcm, 'contrast'))\n",
    "    dissimilarity = np.mean(greycoprops(glcm, 'dissimilarity'))\n",
    "    homogeneity = np.mean(greycoprops(glcm, 'homogeneity'))\n",
    "    energy = np.mean(greycoprops(glcm, 'energy'))\n",
    "    correlation = np.mean(greycoprops(glcm, 'correlation'))\n",
    "\n",
    "    return contrast, dissimilarity, homogeneity, energy, correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_im = path_output\n",
    "path_man = '/content/drive/MyDrive/EIM/Retina/RETINA/Ground truth'\n",
    "path_constr = ''\n",
    "path_test = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_im = os.listdir(path_im)\n",
    "list_man = os.listdir(path_man)\n",
    "\n",
    "n_e_list = []\n",
    "n_j_list = []\n",
    "max_size = []\n",
    "asp_ratio = []\n",
    "\n",
    "for file_im in tqdm(list_man):\n",
    "  image_path_m = os.path.join(path_man,file_im)\n",
    "  image_path = os.path.join(path_im,file_im)\n",
    "  img = Image.open(image_path)\n",
    "  img_m = Image.open(image_path_m)\n",
    "  max_size.append(max(img.size[0], img.size[1]))\n",
    "  asp_ratio.append(img.size[0]/img.size[1])\n",
    "  pic = np.array(img_m)\n",
    "  n_e, n_j = calcola_vasi_per_tipo(pic)\n",
    "  n_e_list.append(n_e)\n",
    "  n_j_list.append(n_j)\n",
    "\n",
    "\n",
    "asp_ratio = asp_ratio -np.min(asp_ratio)/(np.max(asp_ratio)-np.min(asp_ratio))\n",
    "max_size = max_size -np.min(max_size)/(np.max(max_size)-np.min(max_size))\n",
    "n_e_list = n_e_list -np.min(n_e_list)/(np.max(n_e_list)-np.min(n_e_list))\n",
    "n_j_list = n_j_list -np.min(n_j_list)/(np.max(n_j_list)-np.min(n_j_list))\n",
    "\n",
    "asp_ratio = (asp_ratio - np.mean(asp_ratio))/np.std(asp_ratio)\n",
    "max_size = (max_size - np.mean(max_size))/np.std(max_size)\n",
    "n_e_list = (n_e_list - np.mean(n_e_list))/np.std(n_e_list)\n",
    "n_j_list = (n_j_list - np.mean(n_j_list))/np.std(n_j_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2)\n",
    "\n",
    "# Convert lists to NumPy arrays and stack them vertically\n",
    "X = np.hstack((asp_ratio,max_size, n_e_list, n_j_list))  # Transpose to make it a 2D array\n",
    "\n",
    "X_pca = pca.fit_transform(X)\n",
    "\n",
    "kmeans = KMeans(n_clusters=5, random_state=42)\n",
    "y_kmeans = kmeans.fit_predict(X_pca)\n",
    "\n",
    "# Visualize the original data and the obtained clusters\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# Plot original data\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.scatter(X[:, 0], X[:, 1], cmap='viridis', edgecolor='k', s=50)\n",
    "plt.title('Original Data')\n",
    "\n",
    "# Plot data transformed with PCA\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.scatter(X_pca[:, 0], X_pca[:, 1], c=y_kmeans, cmap='viridis', edgecolor='k', s=50)\n",
    "plt.scatter(kmeans.cluster_centers_[:, 0], kmeans.cluster_centers_[:, 1], c='red', marker='X', s=200, label='Centroids')\n",
    "plt.title('PCA + Clustering')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inertias = []\n",
    "\n",
    "for i in range(1,11):\n",
    "    kmeans = KMeans(n_clusters=i, random_state = 0 )\n",
    "    kmeans.fit(X)\n",
    "    inertias.append(kmeans.inertia_)\n",
    "\n",
    "plt.plot(range(1,11), inertias, marker='o')\n",
    "plt.title('Elbow method')\n",
    "plt.xlabel('Number of clusters')\n",
    "plt.ylabel('Inertia')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(X)\n",
    "\n",
    "#!!!!!!!!!!!!!!!\n",
    "#MODIFICA QUA IL NUMERO DI CLUSTER\n",
    "n_clusters = 5                          #<- <- <- <-\n",
    "\n",
    "kmeans = KMeans(n_clusters=3, random_state=42)\n",
    "y_kmeans = kmeans.fit_predict(X_pca)\n",
    "\n",
    "# Visualizza i dati originali e i cluster ottenuti\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# Plot dati originali\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.scatter(X[:,0], X[:,1], cmap='viridis', edgecolor='k', s=50)\n",
    "plt.title('Dati Originali')\n",
    "\n",
    "# Plot dati trasformati con PCA\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.scatter(X_pca[:, 0], X_pca[:, 1], c=y_kmeans, cmap='viridis', edgecolor='k', s=50)\n",
    "plt.scatter(kmeans.cluster_centers_[:, 0], kmeans.cluster_centers_[:, 1], c='red', marker='X', s=200, label='Centroidi')\n",
    "plt.title('PCA + Clustering')\n",
    "plt.legend\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pazconcluster = {}\n",
    "\n",
    "for i in range(len(y_kmeans)):\n",
    "    diz = {}\n",
    "    diz['pz'] = lista_im[i]\n",
    "    diz['cluster'] = y_kmeans[i]\n",
    "    pazconcluster.append(diz)\n",
    "\n",
    "df_paz = pd.DataFrame(pazconcluster)\n",
    "\n",
    "lista_constr = []\n",
    "lista_test = []\n",
    "for i in range(n_clusters-1):\n",
    "    df_cluster = df_paz[df_paz['cluster'] == i]\n",
    "    constr, test = train_test_split(df_cluster, test_size=0.2, random_state=42)\n",
    "    constr_temp = list(constr['pz'])\n",
    "    test_temp = list(test['pz'])\n",
    "    lista_constr = lista_constr + constr_temp\n",
    "    lista_test = lista_test + test_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for pz in lista_constr:\n",
    "    percorso_file_originale = os.path.join(path_im, pz)\n",
    "    percorso_destinazione = os.path.join(path_constr,pz)\n",
    "    shutil.move(percorso_file_originale, percorso_destinazione)\n",
    "\n",
    "for pz in lista_test:\n",
    "    percorso_file_originale = os.path.join(path_im, pz)\n",
    "    percorso_destinazione = os.path.join(path_test,pz)\n",
    "    shutil.move(percorso_file_originale, percorso_destinazione)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
